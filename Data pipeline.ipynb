{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "Billing = pd.read_csv(\"FullData/Billing.csv\")\n",
    "DiseaseCase = pd.read_csv(\"FullData/DiseaseCase.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick looks\n",
    "print(\"Billing information -----\")\n",
    "print(Billing.isnull().sum())\n",
    "print(len(Billing['Patient_ID'].unique()))\n",
    "print(len(Billing.index))\n",
    "print(\"\\nDisease information -----\")\n",
    "print(len(DiseaseCase.index), len(DiseaseCase['Patient_ID'].unique()))\n",
    "print(DiseaseCase['Disease'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows w/o service date\n",
    "Billing = Billing.dropna(subset=['ServiceDate'])\n",
    "print(len(Billing.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare disease case data\n",
    "DiseaseCase['Disease'] = DiseaseCase['Disease'].replace(\"Diabetes Mellitus (ml)\",\"Diabetes Mellitus\") # Make all DM2 diagnosis' the same\n",
    "DiseaseCase['DateOfOnset'] = pd.to_datetime(DiseaseCase.DateOfOnset,format='%Y-%m-%d')\n",
    "DiseaseCase = DiseaseCase.sort_values(by='DateOfOnset', ascending = True)\n",
    "DiseaseCase = DiseaseCase.drop_duplicates(subset = ['Patient_ID'])\n",
    "print(len(DiseaseCase['Patient_ID'].unique()), len(DiseaseCase.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting \n",
    "DM2DF = Billing[pd.to_numeric(Billing.DiagnosisCode_calc,errors='coerce').notnull()] # convert diagnosis codes to floats\n",
    "DM2DF['DiagnosisCode_calc'] = pd.to_numeric(DM2DF['DiagnosisCode_calc']) # convert diagnosis codes to floats\n",
    "DM2DF['ServiceDate'] = pd.to_datetime(DM2DF.ServiceDate,format='%Y-%m-%d')\n",
    "DM2DF = pd.merge(DM2DF,DiseaseCase[['Patient_ID','DateOfOnset']], on='Patient_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get DM2 patients with a complication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The 10 Complications (can be improved)\n",
    "complications = {\n",
    "    'AP' : [float(item/100) for item in range(41300,41400)], # http://www.icd9data.com/2013/Volume1/390-459/410-414/413/default.htm\n",
    "    'AS' : [float(item/100) for item in range(44000,44100)], # http://www.icd9data.com/2012/Volume1/390-459/440-449/440/default.htm\n",
    "    'ICHD' : [float(item/100) for item in range(41400,41500)], # http://www.icd9data.com/2015/Volume1/390-459/410-414/414/default.htm\n",
    "    'DD' : [311], # http://www.icd9data.com/2012/Volume1/290-319/300-316/311/default.htm\n",
    "    'DNP' : [float(item/100) for item in range(58500,58600)] + [581.81], # include 250.4? http://www.icd9data.com/2012/Volume1/580-629/580-589/585/default.htm\n",
    "    'DNU' : [float(item/100) for item in range(35700,35800)], # include 250.6? 357.2 is the exact code http://www.icd9data.com/2012/Volume1/320-389/350-359/357/default.htm \n",
    "    'DR' : [float(item/100) for item in range(36200,36210)], # http://www.icd9data.com/2015/Volume1/320-389/360-379/362/default.htm\n",
    "    'HL' : [389.9], #http://www.icd9data.com/2012/Volume1/320-389/380-389/389/default.htm\n",
    "    'MI' : [float(item/100) for item in range(41000,41100)], #http://www.icd9data.com/2014/Volume1/390-459/410-414/410/default.htm\n",
    "    'PVD' : [float(item/100) for item in range(43300,43400)] #http://www.icd9data.com/2013/Volume1/390-459/440-449/443/default.htm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print # of patients per complication\n",
    "for k,v in complications.items() :\n",
    "    compRows = DM2DF.loc[DM2DF['DiagnosisCode_calc'].isin(v)]\n",
    "    uniqPatients = compRows['Patient_ID'].unique()\n",
    "    print(k, \"has\", len(uniqPatients), \"unique patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find period between DM2 diagnosis and 1st complication diagnosis\n",
    "def DiseasePeriod(compDF) :\n",
    "    compIDs = compDF.sort_values(by='ServiceDate', ascending = True)\n",
    "    compIDs = compIDs[compIDs['ServiceDate'] > compIDs['DateOfOnset']]\n",
    "    compIDs = compIDs.drop_duplicates(subset = ['Patient_ID'])\n",
    "    compIDs = compIDs[['Patient_ID', 'ServiceDate']]\n",
    "    compIDs.columns = ['Patient_ID', 'CompOnset']\n",
    "    return compIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create negative sample using random sampling (can be improved)\n",
    "from random import sample\n",
    "def negativeSamples(posDF) :\n",
    "    # Negative set\n",
    "    NegBillingSet = DM2DF.loc[~DM2DF['Patient_ID'].isin(posDF['Patient_ID'])]\n",
    "    \n",
    "    # Remove patients with only 1 visit and more than 50 visits\n",
    "    NegBillingSet = NegBillingSet[NegBillingSet.groupby('Patient_ID').Patient_ID.transform('count') > 1]\n",
    "    NegBillingSet = NegBillingSet[NegBillingSet.groupby('Patient_ID').Patient_ID.transform('count') < 51]\n",
    "\n",
    "    \n",
    "    # Randomly sample negative class for 1:1 positive negative ratio\n",
    "    NegIDs = NegBillingSet['Patient_ID'].unique().tolist()\n",
    "    NegSample = sample(NegIDs,len(posDF['Patient_ID'].unique()))\n",
    "    NegBillingSample = NegBillingSet.loc[NegBillingSet['Patient_ID'].isin(NegSample)]\n",
    "    \n",
    "    return NegBillingSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gage patient numbers (can delete)\n",
    "temp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return all billing data from disease period (can be improved)\n",
    "def subsetVisits(compCodes) :\n",
    "    \n",
    "    # Subset Billing for complication codes\n",
    "    compDF = DM2DF.loc[DM2DF['DiagnosisCode_calc'].isin(compCodes)]\n",
    "    \n",
    "    # find relevant patientID's and compOnsets\n",
    "    diseasePeriod = DiseasePeriod(compDF)\n",
    "    \n",
    "    # Subset Billing by patient's with complication\n",
    "    bSs = DM2DF.loc[DM2DF['Patient_ID'].isin(diseasePeriod['Patient_ID'])]\n",
    "    \n",
    "    # Merge\n",
    "    bSs = pd.merge(bSs, diseasePeriod, on='Patient_ID')\n",
    "    \n",
    "    # Get rid of visits outside of disease period\n",
    "    relVisits = bSs[(bSs['ServiceDate'] < bSs['CompOnset']) & (bSs['ServiceDate'] >= bSs['DateOfOnset'])]\n",
    "    \n",
    "    #Remove patients with only 1 visit and more than 50\n",
    "    relVisits = relVisits[relVisits.groupby('Patient_ID').Patient_ID.transform('count') > 1] # Change for accuracy\n",
    "    relVisits = relVisits[relVisits.groupby('Patient_ID').Patient_ID.transform('count') < 51]\n",
    "    temp.append(len(relVisits['Patient_ID'].unique()))\n",
    "    \n",
    "    #Merge with negative sample\n",
    "    negSample = negativeSamples(relVisits)\n",
    "    temp.append(len(negSample['Patient_ID'].unique()))\n",
    "    relVisits = relVisits.append(negSample, ignore_index=True)\n",
    "    \n",
    "    return relVisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe wih paitnet ID and visits as index, columns as diags\n",
    "def patientHistories(dataframe) :\n",
    "    AllVisits = {}\n",
    "    for index, row in dataframe.iterrows() :\n",
    "        temp = (str(row['Patient_ID']),str(row['ServiceDate']))\n",
    "        diag = row['DiagnosisCode_calc']\n",
    "        if temp not in AllVisits.keys():\n",
    "            AllVisits[temp] = []\n",
    "        AllVisits[temp] = AllVisits[temp] + [diag]\n",
    "        \n",
    "    PVDF = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in AllVisits.items() ]))\n",
    "    PVDF = PVDF.transpose()\n",
    "    PVDF = PVDF.dropna(axis=0,how='all') # Remove NA\n",
    "    return PVDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call functions on our data\n",
    "subVisits = {} # Billing data\n",
    "seqVisits = {} # Multiindex DF of diags\n",
    "compIDdict = {} # Patient ID's \n",
    "for k, v in complications.items() :\n",
    "    compVisits = subsetVisits(v)\n",
    "    subVisits[k] = compVisits\n",
    "    \n",
    "    CompPatients = compVisits.dropna(subset=['CompOnset'])\n",
    "    CompPatients = CompPatients['Patient_ID'].unique().tolist()\n",
    "    compIDdict[k] = CompPatients\n",
    "    \n",
    "    seqVisits[k] = patientHistories(compVisits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature vector creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check # of unique ICD9 codes\n",
    "print(len(DM2DF['DiagnosisCode_calc'].value_counts().index))\n",
    "\n",
    "# Remove ICD9 codes that only appear 5 or less times\n",
    "ICD9s = DM2DF['DiagnosisCode_calc'].value_counts()\n",
    "ICD9s = ICD9s[DM2DF['DiagnosisCode_calc'].value_counts() > 5]\n",
    "print(ICD9s.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function does 1) one-hot encode each visit 2) SVD to reduce dimensionality 3) Concatenate features and fills in tails\n",
    "def createFeatures(df, codes, IDs) :\n",
    "    RowFeatures = pd.DataFrame(data = 0,\n",
    "                           index = df.index,\n",
    "                           columns=codes.index)\n",
    "    \n",
    "    # if diag occured in a visit, col[diagnosisCode] = 1\n",
    "    for index, row in RowFeatures.iterrows() :\n",
    "        for diag in df.loc[index].dropna() :\n",
    "            row[diag] = 1\n",
    "            \n",
    "    # SVD\n",
    "    U, s, V = np.linalg.svd(RowFeatures)\n",
    "    S = np.zeros((RowFeatures.shape[0], RowFeatures.shape[1]))\n",
    "    S[:RowFeatures.shape[1], :RowFeatures.shape[1]] = np.diag(s)\n",
    "    n_component = 50\n",
    "    S = S[:, :n_component]\n",
    "    reducedMat = U.dot(S)\n",
    "    \n",
    "    reducedDF = pd.DataFrame(data=reducedMat, index=RowFeatures.index)\n",
    "    \n",
    "    # Concatanate patient features\n",
    "    # number at 1st index represents disease status\n",
    "    VisitHistorySVD = {}\n",
    "    for index, row in reducedDF.iterrows() :\n",
    "        temp = int(index[0])\n",
    "        featureVector = list(row)\n",
    "        if temp not in VisitHistorySVD.keys():\n",
    "            if temp in IDs :\n",
    "                VisitHistorySVD[temp] = [1]\n",
    "            else :\n",
    "                VisitHistorySVD[temp] = [0]\n",
    "        VisitHistorySVD[temp] = VisitHistorySVD[temp] + featureVector\n",
    "\n",
    "\n",
    "    # Fill in to 2500\n",
    "    for k,v in VisitHistorySVD.items() :\n",
    "        fillLen = 2501 - len(v)\n",
    "        VisitHistorySVD[k] = v + [0]*fillLen\n",
    "        \n",
    "    return VisitHistorySVD # Dictionary with PatientIDs as keys and encoded data as values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run features (Takes a long time bc of SVD, so run over night)\n",
    "features = {}\n",
    "for k,v in seqVisits.items() :\n",
    "    if k != 'DD' :\n",
    "        print(k)\n",
    "        features[k] = createFeatures(v, ICD9s, compIDdict[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to X and y for modeling\n",
    "X, y = [], []\n",
    "for k,v in VisitHistorySVD.items() :\n",
    "    y.append(v[0])\n",
    "    X.append(v[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.count(1),y.count(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D, GRU, Bidirectional, Input, TimeDistributed, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "print(len(X_train), 'training')\n",
    "print(len(X_test), 'testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional GRU\n",
    "\n",
    "# Random search drop out rate and number of units/neurons\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "input_shape = (X_train.shape[1], 1) #2500,1\n",
    "\n",
    "units = 128\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((50, 50), input_shape=(2500,)))\n",
    "# 1 sees the past \n",
    "# 2 sees the past and the future\n",
    "\n",
    "\n",
    "dropout = 0.2 # for regularization\n",
    "print('Number of hidden units: ', units, 'Dropout: ', dropout)\n",
    "model.add(Bidirectional(GRU(units, input_shape=input_shape))) # 64, $128$, 256, 512\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "print('Training...')\n",
    "history = model.fit(\n",
    "    np.array(X_train),\n",
    "    np.array(y_train),\n",
    "    batch_size = 128, \n",
    "    epochs = 15,\n",
    "    validation_split = 0.1\n",
    ")\n",
    "\n",
    "print(model.evaluate(X_test, np.array(y_test)), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples\n",
    "print(model.predict(X_test[0].reshape(1,2500)), y_test[0])\n",
    "print(model.predict(X_test[1].reshape(1,2500)), y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss per epoch\n",
    "plt.clf()\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy per epoch\n",
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1) #?\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'y', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with RF and MLP\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from time import time\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Random Forest\", \"MLP\"]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=100),\n",
    "    MLPClassifier()\n",
    "]\n",
    "\n",
    "print(\"{0:20}{1:40}\\n-----------------------------------------------------\".\\\n",
    "      format(\"Classifier\", \"Accuracy\"))\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    \n",
    "    start_time = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    end_time = time()\n",
    "    print(\"{0:20}{1:40}{2:40}\".format(name, str(score), (end_time - start_time)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
